<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mahan Pouromidi - ML Scientist</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        :root {
            --primary: #2563eb;
            --primary-dark: #1e40af;
            --text-dark: #1e293b;
            --text-light: #64748b;
            --bg-light: #f8fafc;
            --border: #e2e8f0;
            --accent: #06b6d4;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.7;
            color: var(--text-dark);
            background: #ffffff;
        }

        .container {
            max-width: 1100px;
            margin: 0 auto;
            padding: 0 2rem;
        }

        /* Header */
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 5rem 0 4rem;
            position: relative;
            overflow: hidden;
        }

        header::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: url('data:image/svg+xml,<svg width="100" height="100" xmlns="http://www.w3.org/2000/svg"><defs><pattern id="grid" width="40" height="40" patternUnits="userSpaceOnUse"><path d="M 40 0 L 0 0 0 40" fill="none" stroke="rgba(255,255,255,0.1)" stroke-width="1"/></pattern></defs><rect width="100" height="100" fill="url(%23grid)"/></svg>');
            opacity: 0.3;
        }

        .header-content {
            position: relative;
            z-index: 1;
        }

        h1 {
            font-size: 3rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            letter-spacing: -0.02em;
        }

        .subtitle {
            font-size: 1.3rem;
            opacity: 0.95;
            font-weight: 300;
            margin-bottom: 2rem;
        }

        .contact-links {
            display: flex;
            gap: 1.5rem;
            flex-wrap: wrap;
            margin-top: 1.5rem;
        }

        .contact-links a {
            color: white;
            text-decoration: none;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: rgba(255, 255, 255, 0.15);
            border-radius: 8px;
            transition: all 0.3s ease;
            backdrop-filter: blur(10px);
        }

        .contact-links a:hover {
            background: rgba(255, 255, 255, 0.25);
            transform: translateY(-2px);
        }

        /* Navigation */
        nav {
            background: white;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            position: sticky;
            top: 0;
            z-index: 100;
        }

        nav ul {
            list-style: none;
            display: flex;
            gap: 0;
            justify-content: center;
        }

        nav a {
            display: block;
            padding: 1rem 1.5rem;
            color: var(--text-dark);
            text-decoration: none;
            font-weight: 500;
            transition: all 0.3s ease;
            position: relative;
        }

        nav a::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            right: 0;
            height: 3px;
            background: var(--primary);
            transform: scaleX(0);
            transition: transform 0.3s ease;
        }

        nav a:hover {
            color: var(--primary);
        }

        nav a:hover::after {
            transform: scaleX(1);
        }

        /* Sections */
        section {
            padding: 4rem 0;
        }

        section:nth-child(even) {
            background: var(--bg-light);
        }

        h2 {
            font-size: 2rem;
            margin-bottom: 2rem;
            color: var(--text-dark);
            position: relative;
            display: inline-block;
        }

        h2::after {
            content: '';
            position: absolute;
            bottom: -8px;
            left: 0;
            width: 60px;
            height: 4px;
            background: linear-gradient(90deg, var(--primary), var(--accent));
            border-radius: 2px;
        }

        /* About */
        .about-content {
            font-size: 1.1rem;
            color: var(--text-light);
            max-width: 800px;
        }

        .highlights {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 1.5rem;
            margin-top: 2rem;
        }

        .highlight-card {
            background: white;
            padding: 1.5rem;
            border-radius: 12px;
            border: 1px solid var(--border);
            transition: all 0.3s ease;
        }

        .highlight-card:hover {
            transform: translateY(-4px);
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        }

        .highlight-card h3 {
            color: var(--primary);
            margin-bottom: 0.5rem;
            font-size: 1.1rem;
        }

        /* Education & Experience */
        .timeline-item {
            background: white;
            padding: 2rem;
            border-radius: 12px;
            margin-bottom: 1.5rem;
            border-left: 4px solid var(--primary);
            transition: all 0.3s ease;
        }

        .timeline-item:hover {
            box-shadow: 0 5px 20px rgba(0,0,0,0.08);
            transform: translateX(4px);
        }

        .timeline-header {
            display: flex;
            justify-content: space-between;
            align-items: start;
            margin-bottom: 1rem;
            flex-wrap: wrap;
            gap: 0.5rem;
        }

        .timeline-title {
            font-size: 1.3rem;
            font-weight: 600;
            color: var(--text-dark);
        }

        .timeline-subtitle {
            color: var(--primary);
            font-weight: 500;
        }

        .timeline-date {
            color: var(--text-light);
            font-size: 0.95rem;
            white-space: nowrap;
        }

        .timeline-item ul {
            margin-left: 1.5rem;
            color: var(--text-light);
        }

        .timeline-item li {
            margin-bottom: 0.5rem;
        }

        /* Publications */
        .publication {
            background: white;
            padding: 1.5rem;
            border-radius: 12px;
            margin-bottom: 1rem;
            border: 1px solid var(--border);
            transition: all 0.3s ease;
        }

        .publication:hover {
            border-color: var(--primary);
            box-shadow: 0 4px 12px rgba(37, 99, 235, 0.1);
        }

        .pub-title {
            font-weight: 600;
            color: var(--text-dark);
            margin-bottom: 0.5rem;
            font-size: 1.05rem;
        }

        .pub-venue {
            color: var(--primary);
            font-weight: 500;
            font-size: 0.95rem;
        }

        /* Skills */
        .skills-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 1.5rem;
        }

        .skill-category {
            background: white;
            padding: 1.5rem;
            border-radius: 12px;
            border: 1px solid var(--border);
        }

        .skill-category h3 {
            color: var(--primary);
            margin-bottom: 1rem;
            font-size: 1.1rem;
        }

        .skill-category p {
            color: var(--text-light);
            line-height: 1.8;
        }

        /* Projects */
        .projects-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
        }

        .project-card {
            background: white;
            border-radius: 12px;
            overflow: hidden;
            border: 1px solid var(--border);
            transition: all 0.3s ease;
        }

        .project-card:hover {
            transform: translateY(-8px);
            box-shadow: 0 12px 40px rgba(0,0,0,0.12);
        }

        .project-content {
            padding: 1.5rem;
        }

        .project-card h3 {
            color: var(--text-dark);
            margin-bottom: 1rem;
            font-size: 1.2rem;
        }

        .project-card ul {
            margin-left: 1.2rem;
            color: var(--text-light);
        }

        .project-card li {
            margin-bottom: 0.5rem;
        }

        /* Footer */
        footer {
            background: var(--text-dark);
            color: white;
            text-align: center;
            padding: 2rem 0;
            margin-top: 4rem;
        }

        /* Responsive */
        @media (max-width: 768px) {
            h1 {
                font-size: 2rem;
            }

            .subtitle {
                font-size: 1.1rem;
            }

            nav ul {
                flex-wrap: wrap;
            }

            nav a {
                padding: 0.75rem 1rem;
                font-size: 0.9rem;
            }

            .timeline-header {
                flex-direction: column;
            }

            section {
                padding: 3rem 0;
            }
        }

        /* Smooth scroll */
        html {
            scroll-behavior: smooth;
        }
    </style>
</head>
<body>
    <header>
        <div class="container header-content">
            <h1>Mahan Pouromidi</h1>
            <p class="subtitle">Machine Learning Scientist | Computer Vision & Medical Imaging</p>
            <div class="contact-links">
                <a href="mailto:mahanpre@gmail.com">✉ mahanpre@gmail.com</a>
                <a href="tel:+14164521378">📞 (+1) 416-452-1378</a>
                <a href="https://linkedin.com/in/Mahan-Pouromidi" target="_blank">💼 LinkedIn</a>
                <a href="https://github.com/mahanpro" target="_blank">💻 GitHub</a>
            </div>
        </div>
    </header>

    <nav>
        <ul>
            <li><a href="#about">About</a></li>
            <li><a href="#experience">Experience</a></li>
            <li><a href="#education">Education</a></li>
            <li><a href="#publications">Publications</a></li>
            <li><a href="#projects">Projects</a></li>
            <li><a href="#skills">Skills</a></li>
        </ul>
    </nav>

    <section id="about">
        <div class="container">
            <h2>About Me</h2>
            <div class="about-content">
                <p>Master's graduate in Biomedical Engineering with expertise in computer vision, deep learning, and medical imaging. Currently working as a Machine Learning Scientist at BC Cancer, developing advanced multimodal vision-language models for automated tumor segmentation in PET/CT imaging.</p>
            </div>
            <div class="highlights">
                <div class="highlight-card">
                    <h3>🎓 Academic Excellence</h3>
                    <p>Master's GPA: 3.97/4.0 from McMaster University</p>
                </div>
                <div class="highlight-card">
                    <h3>📝 Research Impact</h3>
                    <p>First-author publication at SPIE Medical Imaging 2025</p>
                </div>
                <div class="highlight-card">
                    <h3>🚀 Innovation</h3>
                    <p>Developing report-guided vision-language models for medical imaging</p>
                </div>
            </div>
        </div>
    </section>

    <section id="experience">
        <div class="container">
            <h2>Experience</h2>
            
            <div class="timeline-item">
                <div class="timeline-header">
                    <div>
                        <div class="timeline-title">Machine Learning Scientist</div>
                        <div class="timeline-subtitle">BC Cancer, Vancouver, BC</div>
                    </div>
                    <div class="timeline-date">June 2025 – Present</div>
                </div>
                <ul>
                    <li>Led development of report-guided vision-language pipeline for whole-body PSMA PET/CT using 3D SegResNet with decoder cross-attention</li>
                    <li>Implemented multimodal text features with token loaders for LLM embeddings and sanitization</li>
                    <li>Engineered CrossAttention3D with InstanceNorm/LayerNorm stabilization and multi-head attention</li>
                    <li>Achieved statistically significant reductions in false positive lesion predictions</li>
                </ul>
            </div>

            <div class="timeline-item">
                <div class="timeline-header">
                    <div>
                        <div class="timeline-title">Software Developer Intern (Fullstack)</div>
                        <div class="timeline-subtitle">Biophotonics Lab, Hamilton, Ontario</div>
                    </div>
                    <div class="timeline-date">Jul 2024 – Feb 2025</div>
                </div>
                <ul>
                    <li>Built low-latency streaming service for dual camera feeds with TLS and authentication</li>
                    <li>Designed PostgreSQL schemas and CRUD APIs with JWT authentication</li>
                    <li>Implemented Next.js server components to optimize TTFB for stream dashboards</li>
                </ul>
            </div>

            <div class="timeline-item">
                <div class="timeline-header">
                    <div>
                        <div class="timeline-title">Graduate Research Assistant</div>
                        <div class="timeline-subtitle">McMaster University, Hamilton, Ontario</div>
                    </div>
                    <div class="timeline-date">Sep 2022 – Sep 2024</div>
                </div>
                <ul>
                    <li>Comprehensive evaluation of convolutional vs transformer models for 3D PET/CT tumor segmentation</li>
                    <li>Achieved state-of-the-art F1 = 0.70 on multi-cancer imbalanced dataset</li>
                    <li>Optimized SAM mask-decoder with ONNX, reducing inference latency by 25% and memory by 150 MB</li>
                    <li>Published first-author paper accepted at SPIE Medical Imaging 2025</li>
                </ul>
            </div>

            <div class="timeline-item">
                <div class="timeline-header">
                    <div>
                        <div class="timeline-title">Researcher & Algorithm Developer</div>
                        <div class="timeline-subtitle">NABZ Group, Tehran, Tehran</div>
                    </div>
                    <div class="timeline-date">Apr 2021 – Dec 2021</div>
                </div>
                <ul>
                    <li>Developed adaptive filtering and DSP algorithms for ECG signal denoising</li>
                    <li>Improved denoising accuracy by 15% and runtime efficiency by 40%</li>
                    <li>Investigated multi-scale methods including EMD, ICA, and Wavelet Transform</li>
                </ul>
            </div>
        </div>
    </section>

    <section id="education">
        <div class="container">
            <h2>Education</h2>
            
            <div class="timeline-item">
                <div class="timeline-header">
                    <div>
                        <div class="timeline-title">Master of Applied Sciences in Biomedical Engineering</div>
                        <div class="timeline-subtitle">McMaster University, Hamilton, Ontario</div>
                    </div>
                    <div class="timeline-date">Sep 2022 – Sep 2024</div>
                </div>
                <p><strong>GPA: 3.97/4.0</strong></p>
                <p><strong>Thesis:</strong> An Investigation of Advanced Deep Learning-Based Automated Models for Tumor Segmentation in Whole-Body PET/CT Images</p>
                <p><strong>Supervisor:</strong> Dr. Ashirbani Saha</p>
            </div>

            <div class="timeline-item">
                <div class="timeline-header">
                    <div>
                        <div class="timeline-title">Bachelor of Science in Electrical Engineering</div>
                        <div class="timeline-subtitle">Amirkabir University of Technology, Tehran</div>
                    </div>
                    <div class="timeline-date">Sep 2017 – Mar 2022</div>
                </div>
                <p><strong>GPA: 3.6/4.0</strong></p>
                <p><strong>Thesis:</strong> Fire Detection Using Neural Networks and Thermal</p>
                <p><strong>Supervisor:</strong> Dr. Amir Jahanshahi</p>
                <p style="margin-top: 1rem;"><strong>Honors:</strong></p>
                <ul>
                    <li>Ranked within top 0.5% in university entrance exam among ~150,000 participants</li>
                    <li>Granted admission to study second major (offered to students with high GPA)</li>
                </ul>
            </div>
        </div>
    </section>

    <section id="publications">
        <div class="container">
            <h2>Publications</h2>
            
            <div class="publication">
                <div class="pub-title">Is segmentation performance of deep-learning models affected by cancer type? A performance analysis on PET/CT</div>
                <div class="pub-venue">SPIE Medical Imaging 2025</div>
                <p style="margin-top: 0.5rem; color: var(--text-light);">Pouromidi, M., et al.</p>
            </div>

            <div class="publication">
                <div class="pub-title">Report-Guided Vision–Language Segmentation for PSMA PET/CT</div>
                <div class="pub-venue">Manuscript in preparation for Journal of Nuclear Medicine or EJNMMI, 2025</div>
                <p style="margin-top: 0.5rem; color: var(--text-light);">Pouromidi, M., Bayasi, N., Yousefirizi, F., Rahmim, A.</p>
            </div>
        </div>
    </section>

    <section id="projects">
        <div class="container">
            <h2>Projects</h2>
            <div class="projects-grid">
                <div class="project-card">
                    <div class="project-content">
                        <h3>NeuroLens (Genesis AI Hackathon)</h3>
                        <ul>
                            <li>AI-powered assistive system for visually impaired users</li>
                            <li>Real-time object detection (YOLOv8) and OCR with voice interaction</li>
                            <li>Optimized WebSocket backend for sub-second response times</li>
                            <li>OpenAI agents for triage, vision, TTS, STT, and environment description</li>
                        </ul>
                    </div>
                </div>

                <div class="project-card">
                    <div class="project-content">
                        <h3>MedChatBot: Medical Assistant</h3>
                        <ul>
                            <li>Retrieval-augmented chatbot on 47K medical Q&A pairs</li>
                            <li>Context-aware responses using Llama 3.2</li>
                            <li>FAISS vector store for efficient similarity search</li>
                            <li>FastAPI backend with Next.js frontend</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="skills">
        <div class="container">
            <h2>Technical Skills</h2>
            <div class="skills-grid">
                <div class="skill-category">
                    <h3>Machine Learning & Deep Learning</h3>
                    <p>PyTorch, TensorFlow, MONAI, scikit-learn, PyTorch Lightning, ONNX, multimodal learning, self-supervised learning, transfer learning</p>
                </div>

                <div class="skill-category">
                    <h3>Computer Vision & Medical Imaging</h3>
                    <p>CNNs, Vision Transformers, SAM, U-Net/SegResNet, image segmentation, registration, preprocessing, 3D volumetric data</p>
                </div>

                <div class="skill-category">
                    <h3>NLP & Multimodal Models</h3>
                    <p>Transformers, BERT, CLIP, LLaMA, cross-attention fusion, vision-language integration, report-guided analysis</p>
                </div>

                <div class="skill-category">
                    <h3>Programming & Tools</h3>
                    <p>Python (NumPy, pandas, matplotlib), C/C++, Git, Linux, Docker, REST APIs</p>
                </div>

                <div class="skill-category">
                    <h3>Cloud & Infrastructure</h3>
                    <p>AWS (EC2, S3, SageMaker), GPU training, distributed data parallel, mixed precision, reproducible pipelines</p>
                </div>
            </div>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>&copy; 2025 Mahan Pouromidi. All rights reserved.</p>
        </div>
    </footer>
</body>
</html>